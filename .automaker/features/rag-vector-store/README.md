# RAG Vector Store Implementation

## Overview

This implementation adds vector database capabilities to the Legal AI Platform using **pgvector** extension for PostgreSQL. The system stores document embeddings for semantic search and Retrieval Augmented Generation (RAG).

## Architecture

### Backend Components

1. **DocumentEmbedding Entity** (`apps/backend/src/modules/documents/entities/document-embedding.entity.ts`)
   - Stores document chunks and their vector embeddings
   - Uses pgvector's vector type with 1536 dimensions (OpenAI text-embedding-3-small)
   - Includes metadata and chunk indexing

2. **VectorStoreService** (`apps/backend/src/modules/documents/services/vector-store.service.ts`)
   - `indexDocument()`: Chunks text and generates embeddings for storage
   - `similaritySearch()`: Performs vector similarity search using cosine distance
   - `deleteDocumentEmbeddings()`: Removes embeddings when document is deleted
   - Handles text chunking with overlap for better context

3. **AiClientService** (updated)
   - `generateEmbeddings()`: Calls AI Engine to generate embeddings

### AI Engine Components

1. **EmbeddingService** (`apps/ai-engine/src/services/embedding_service.py`)
   - Generates embeddings using OpenAI's text-embedding-3-small model
   - Supports batch embedding generation for efficiency

2. **New API Endpoint**
   - `POST /api/v1/embeddings/generate`: Generate embeddings for text chunks

## Database Setup

### Prerequisites

1. Install pgvector extension in PostgreSQL:
   ```bash
   # Connect to your database
   psql -U postgres -d legal_ai_db

   # Create extension
   CREATE EXTENSION IF NOT EXISTS vector;
   ```

2. The `document_embeddings` table will be auto-created by TypeORM synchronize in development.

### Table Schema

```sql
CREATE TABLE document_embeddings (
  id UUID PRIMARY KEY,
  document_id UUID NOT NULL,
  embedding vector(1536) NOT NULL,
  content_chunk TEXT NOT NULL,
  chunk_index INT NOT NULL,
  chunk_size INT NOT NULL,
  metadata JSONB,
  created_at TIMESTAMP DEFAULT NOW()
);
```

### Indexing

Create an HNSW index for fast similarity search (optional but recommended):

```sql
CREATE INDEX ON document_embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

## Usage Examples

### Indexing a Document

```typescript
// In DocumentsService or a background job
async indexDocumentForSearch(documentId: string, content: string) {
  await this.vectorStoreService.indexDocument(documentId, content, {
    chunkSize: 500,      // Characters per chunk
    chunkOverlap: 50,    // Overlap between chunks
    metadata: {
      title: 'Document Title',
      type: 'LAWSUIT',
      createdAt: new Date(),
    }
  });
}
```

### Semantic Search

```typescript
// Find similar documents
const results = await this.vectorStoreService.similaritySearch(
  queryEmbedding,  // Generated by AI Engine
  5,               // Limit to top 5 results
  0.7,             // Minimum similarity threshold
  documentId       // Optional: filter by specific document
);

// Results include:
// - contentChunk: Relevant text snippet
// - similarity: Score (0-1)
// - metadata: Document metadata
```

### Generating Embeddings

```typescript
// In any service
const chunks = ['First chunk of text', 'Second chunk of text'];
const embeddings = await this.aiClient.generateEmbeddings(chunks);
// Returns: number[][]
```

## Integration with Document Lifecycle

To automatically index documents when they're created or updated:

1. **In DocumentsService**, after document generation completes:
   ```typescript
   // When document status becomes COMPLETED
   if (document.status === DocumentStatus.COMPLETED && document.content) {
     await this.vectorStoreService.indexDocument(
       document.id,
       document.content
     );
   }
   ```

2. **Before deleting a document**, remove embeddings:
   ```typescript
   await this.vectorStoreService.deleteDocumentEmbeddings(documentId);
   ```

## Polish Legal Text Indexing

For optimal indexing of Polish legal texts:

1. **Chunking strategy**:
   - Default: 500 characters with 50-character overlap
   - Preserves paragraph boundaries for semantic coherence
   - Adjust based on document type (statutes, court rulings, etc.)

2. **Metadata suggestions**:
   ```typescript
   metadata: {
     language: 'pl',
     documentType: 'USTAWA' | 'WYROK' | 'POZEW',
     court: 'Sąd Rejonowy',
     date: '2024-01-15',
     keywords: ['rozwód', 'alimenty'],
   }
   ```

3. **Indexing pipeline**:
   - Import legal texts from external sources (ISAP, court databases)
   - Clean and normalize text
   - Generate embeddings in batches (max 100 texts per request)
   - Store in vector database with metadata

## Performance Considerations

1. **Batch Processing**: Generate embeddings for multiple chunks in a single API call
2. **Async Indexing**: Use Bull queue to index documents in background
3. **HNSW Index**: Recommended for >10,000 embeddings
4. **Connection Pooling**: Configured in app.module.ts (max: 20 connections)

## Future Enhancements

1. **Hybrid Search**: Combine vector similarity with full-text search (tsvector)
2. **Reranking**: Use cross-encoder for improved relevance
3. **Multi-language**: Support embeddings for multiple languages
4. **Document Summaries**: Index document summaries alongside chunks
5. **Citations**: Link embeddings to specific legal articles/paragraphs

## Troubleshooting

### pgvector extension not found
```bash
# Install pgvector (Ubuntu/Debian)
sudo apt-get install postgresql-16-pgvector

# Or build from source
git clone --branch v0.2.1 https://github.com/pgvector/pgvector.git
cd pgvector
make
sudo make install
```

### Embedding dimension mismatch
Ensure all embeddings use the same dimension (1536 for text-embedding-3-small).

### Slow similarity search
Create HNSW index: `CREATE INDEX ON document_embeddings USING hnsw (embedding vector_cosine_ops);`

## Testing

See verification tests in: `tests/vector-store.spec.ts`
