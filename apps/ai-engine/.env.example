# AI Engine Environment Variables
# Copy this file to .env and configure with your values

# -----------------------------------------------------------------------------
# OpenAI Settings (Required for AI features)
# -----------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Model configuration
OPENAI_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# -----------------------------------------------------------------------------
# Service Settings
# -----------------------------------------------------------------------------
# Port and host for the FastAPI server
AI_ENGINE_PORT=8000
AI_ENGINE_HOST=0.0.0.0

# Backend API URL (for vector store integration)
BACKEND_URL=http://localhost:3001

# Frontend URL (for CORS configuration)
FRONTEND_URL=http://localhost:3000

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# Langfuse Observability Settings (Optional)
# -----------------------------------------------------------------------------
# Langfuse provides AI observability including LLM tracing, token usage,
# cost monitoring, and performance analytics.
#
# Get your credentials from: https://cloud.langfuse.com
# For self-hosted Langfuse, see: https://langfuse.com/docs/self-host

# Public key for Langfuse authentication
# Format: Must start with "pk-" (e.g., pk-xxxxxxxxxxxxxxxxxxxx)
# Leave empty to disable Langfuse tracing (also set LANGFUSE_ENABLED=false)
LANGFUSE_PUBLIC_KEY=

# Secret key for Langfuse authentication
# Format: Must start with "sk-" (e.g., sk-xxxxxxxxxxxxxxxxxxxx)
# Must be set together with LANGFUSE_PUBLIC_KEY
LANGFUSE_SECRET_KEY=

# Langfuse server URL
# - For Langfuse Cloud: https://cloud.langfuse.com (default, leave empty)
# - For self-hosted: e.g., http://localhost:3000 or https://langfuse.yourdomain.com
LANGFUSE_HOST=

# Enable or disable Langfuse tracing
# Set to "true" to enable, "false" to disable
# If enabled, both LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY must be set
LANGFUSE_ENABLED=true

# Sampling rate determines what percentage of requests are traced
# - 1.0 = Trace 100% of requests (recommended for development)
# - 0.5 = Trace 50% of requests
# - 0.1 = Trace 10% of requests (recommended for high-traffic production)
# - 0.0 = Trace no requests
LANGFUSE_SAMPLING_RATE=1.0

# HTTP header name to use for session ID tracking
# The frontend should send this header to correlate traces with user sessions
LANGFUSE_SESSION_ID_HEADER=x-session-id

# -----------------------------------------------------------------------------
# Cache Settings (Optional)
# -----------------------------------------------------------------------------
# Redis URL for distributed caching (leave empty for in-memory cache)
REDIS_URL=

# Cache configuration
CACHE_ENABLED=true
CACHE_TTL_SECONDS=3600
CACHE_MAX_SIZE=1000

# -----------------------------------------------------------------------------
# Cost Monitoring Settings
# -----------------------------------------------------------------------------
# Alert threshold in USD for daily cost
COST_ALERT_THRESHOLD_USD=10.0

# Enable/disable cost tracking
COST_TRACKING_ENABLED=true

# Maximum tokens per request (safety limit)
MAX_TOKENS_PER_REQUEST=100000

# -----------------------------------------------------------------------------
# Model Selection Settings
# -----------------------------------------------------------------------------
# Automatically choose model based on task complexity
AUTO_MODEL_SELECTION=true

# Prefer gpt-4o-mini for simple tasks (cost optimization)
PREFER_MINI_MODEL=true
